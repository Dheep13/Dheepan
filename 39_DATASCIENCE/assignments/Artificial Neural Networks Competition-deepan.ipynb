{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPy/cGJmNuwcUpj/Ya+L510"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import files\n","\n","# This will prompt you to select the kaggle.json file\n","files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"h3SGoExDui89","executionInfo":{"status":"ok","timestamp":1709526695824,"user_tz":-330,"elapsed":22401,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"4080dfb7-5369-4465-d4e5-34e657e14da1"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-e3ecc8fb-e434-41dc-ae11-510f600ab585\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-e3ecc8fb-e434-41dc-ae11-510f600ab585\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"deepanshanmugam\",\"key\":\"c0b8b2f3db364205fece69dccfe97e0a\"}'}"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"5s17001bunjy","executionInfo":{"status":"ok","timestamp":1709526930349,"user_tz":-330,"elapsed":373,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!kaggle competitions download -c copy-of-artificial-neural-networks-competition --force"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3ApVJHvurbr","executionInfo":{"status":"ok","timestamp":1709526934847,"user_tz":-330,"elapsed":1447,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"8d6e42a3-5e0b-420b-d784-69e2035ffba4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading copy-of-artificial-neural-networks-competition.zip to /content\n","\r  0% 0.00/28.7M [00:00<?, ?B/s]\r 70% 20.0M/28.7M [00:00<00:00, 206MB/s]\n","\r100% 28.7M/28.7M [00:00<00:00, 184MB/s]\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHxSPIt9wk0m","executionInfo":{"status":"ok","timestamp":1709527276176,"user_tz":-330,"elapsed":24976,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"0f5fe61e-de4a-4c74-b13c-56948436bcfa"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!unzip '/content/drive/My Drive/Colab Notebooks/copy-of-artificial-neural-networks-competition.zip' -d '/content/dataset'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYTsQpn-xCyW","executionInfo":{"status":"ok","timestamp":1709527377483,"user_tz":-330,"elapsed":2146,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"c93dd0a7-4b84-4ac8-c5ce-b04dbd8ec66b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/My Drive/Colab Notebooks/copy-of-artificial-neural-networks-competition.zip\n","  inflating: /content/dataset/sample_submission.csv  \n","  inflating: /content/dataset/test.csv  \n","  inflating: /content/dataset/train_mpst.csv  \n","  inflating: /content/dataset/val.csv  \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Adjust the filename and path as necessary\n","file_path = '/content/dataset/train_mpst.csv'  # Example for accessing the training dataset\n","train_df = pd.read_csv(file_path)\n","train_df.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":568},"id":"sB70NKA2xfHm","executionInfo":{"status":"ok","timestamp":1709527485075,"user_tz":-330,"elapsed":969,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"84bc21d0-9861-48fd-82c7-1e21aa57881a"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     imdb_id                                          title  \\\n","0  tt0057603                        I tre volti della paura   \n","1  tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n","2  tt0113862                             Mr. Holland's Opus   \n","3  tt0249380                                      Baise-moi   \n","4  tt0408790                                     Flightplan   \n","\n","                                       plot_synopsis synopsis_source  absurd  \\\n","0  Note: this synopsis is for the orginal Italian...            imdb       0   \n","1  Two thousand years ago, Nhagruul the Foul, a s...            imdb       0   \n","2  Glenn Holland, not a morning person by anyone'...            imdb       0   \n","3  Baise-moi tells the story of Nadine and Manu w...       wikipedia       0   \n","4  Kyle Pratt (Jodie Foster) is a propulsion engi...            imdb       0   \n","\n","   action  adult comedy  allegory  alternate history  alternate reality  ...  \\\n","0       0             0         0                  0                  0  ...   \n","1       0             0         0                  0                  0  ...   \n","2       0             0         0                  0                  0  ...   \n","3       0             0         0                  0                  0  ...   \n","4       1             0         0                  0                  0  ...   \n","\n","   sentimental  storytelling  stupid  suicidal  suspenseful  \\\n","0            0             0       0         0            0   \n","1            0             0       0         0            0   \n","2            0             0       1         0            0   \n","3            0             0       0         0            0   \n","4            0             0       0         0            1   \n","\n","   thought-provoking  tragedy  violence  western  whimsical  \n","0                  0        0         0        0          0  \n","1                  0        0         1        0          0  \n","2                  0        0         0        0          0  \n","3                  0        0         1        0          0  \n","4                  0        0         0        0          0  \n","\n","[5 rows x 75 columns]"],"text/html":["\n","  <div id=\"df-886e1e2d-6bec-4f48-9b11-467e8c095745\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>imdb_id</th>\n","      <th>title</th>\n","      <th>plot_synopsis</th>\n","      <th>synopsis_source</th>\n","      <th>absurd</th>\n","      <th>action</th>\n","      <th>adult comedy</th>\n","      <th>allegory</th>\n","      <th>alternate history</th>\n","      <th>alternate reality</th>\n","      <th>...</th>\n","      <th>sentimental</th>\n","      <th>storytelling</th>\n","      <th>stupid</th>\n","      <th>suicidal</th>\n","      <th>suspenseful</th>\n","      <th>thought-provoking</th>\n","      <th>tragedy</th>\n","      <th>violence</th>\n","      <th>western</th>\n","      <th>whimsical</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tt0057603</td>\n","      <td>I tre volti della paura</td>\n","      <td>Note: this synopsis is for the orginal Italian...</td>\n","      <td>imdb</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>tt1733125</td>\n","      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n","      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n","      <td>imdb</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>tt0113862</td>\n","      <td>Mr. Holland's Opus</td>\n","      <td>Glenn Holland, not a morning person by anyone'...</td>\n","      <td>imdb</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>tt0249380</td>\n","      <td>Baise-moi</td>\n","      <td>Baise-moi tells the story of Nadine and Manu w...</td>\n","      <td>wikipedia</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>tt0408790</td>\n","      <td>Flightplan</td>\n","      <td>Kyle Pratt (Jodie Foster) is a propulsion engi...</td>\n","      <td>imdb</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 75 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-886e1e2d-6bec-4f48-9b11-467e8c095745')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-886e1e2d-6bec-4f48-9b11-467e8c095745 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-886e1e2d-6bec-4f48-9b11-467e8c095745');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0114e6fa-0934-47b5-88c9-deaea5467fa1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0114e6fa-0934-47b5-88c9-deaea5467fa1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0114e6fa-0934-47b5-88c9-deaea5467fa1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_df"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# Step 2: Data Cleaning and Preprocessing\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","# Download NLTK data (you may skip this if you've already done it)\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Function to clean text data\n","def clean_text(text):\n","    # Remove HTML tags\n","    text = re.sub(r'<[^>]*>', '', text)\n","    # Remove punctuation and numbers\n","    text = re.sub('[^a-zA-Z]', ' ', text)\n","    # Convert text to lowercase\n","    text = text.lower()\n","    # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text)\n","    return text\n","\n","# Apply the cleaning function to the plot_synopsis column\n","train_df['cleaned_plot'] = train_df['plot_synopsis'].apply(clean_text)\n","\n","# Step 3: Text Vectorization (TF-IDF)\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Initialize TF-IDF Vectorizer\n","tfidf_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n","\n","# Fit and transform the cleaned plot synopsis text\n","X_tfidf = tfidf_vectorizer.fit_transform(train_df['cleaned_plot'])\n","\n","# For multi-label classification, ensure labels are properly encoded\n","# Assuming labels are in separate columns following 'plot_synopsis', 'imdb_id', etc.\n","# Convert DataFrame label columns to a list of lists\n","\n","# Assuming the DataFrame 'train_df' holds your data, and label columns are correctly identified\n","label_columns = train_df.columns[4:75]  # Adjust indices as necessary\n","labels_list = train_df[label_columns].apply(lambda row: row.index[row == 1].tolist(), axis=1)\n","labels = train_df[label_columns]\n","mlb = MultiLabelBinarizer()\n","y = mlb.fit_transform(labels_list)\n","\n","print(y.shape)  # Should now match the number of rows in 'X_tfidf'\n","print( X_tfidf.shape)  # Should now match the number of rows in 'X_tfidf'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABqKMmMUyStg","executionInfo":{"status":"ok","timestamp":1709528806791,"user_tz":-330,"elapsed":14753,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"1dec2a39-c0a5-4c5f-fa59-544e01c63098"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["(9489, 71)\n","(9489, 10000)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n","\n","print(X_train.shape)  # Should now match the number of rows in 'X_tfidf'\n","print( y_val.shape)  # Should now match the number of rows in 'X_tfidf'\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVFDu3no1IYw","executionInfo":{"status":"ok","timestamp":1709537312188,"user_tz":-330,"elapsed":444,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"d3bf5379-8943-4990-9e51-e27aabd26b49"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["(7591, 10000)\n","(1898, 71)\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","from scipy.sparse import csr_matrix\n","\n","# Convert the Scipy sparse matrix to a dense NumPy array\n","# This step is necessary because PyTorch doesn't support sparse matrices as input for fully connected layers directly\n","X_train_dense = X_train.toarray() if isinstance(X_train, csr_matrix) else X_train\n","X_val_dense = X_val.toarray() if isinstance(X_val, csr_matrix) else X_val\n","\n","# Convert data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train_dense, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","X_val_tensor = torch.tensor(X_val_dense, dtype=torch.float32)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n","\n","# Create TensorDatasets\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n","\n","# Create DataLoaders\n","batch_size = 64\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","print(X_train_tensor.shape)  # Should now match the number of rows in 'X_tfidf'\n","print( X_val_tensor.shape)  # Should now match the number of rows in 'X_tfidf'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9kbC4fe3FeT","executionInfo":{"status":"ok","timestamp":1709537365631,"user_tz":-330,"elapsed":3690,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"4767f814-0822-45d6-9ae8-a0529df0e488"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([7591, 10000])\n","torch.Size([1898, 10000])\n"]}]},{"cell_type":"code","source":["from torch import nn\n","\n","class MultiLabelNN(nn.Module):\n","    def __init__(self, num_features, num_labels):\n","        super(MultiLabelNN, self).__init__()\n","        self.layer1 = nn.Linear(num_features, 512)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.5)\n","        self.layer2 = nn.Linear(512, 256)\n","        self.output_layer = nn.Linear(256, num_labels)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.relu(self.layer1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.layer2(x))\n","        x = self.dropout(x)\n","        x = self.sigmoid(self.output_layer(x))\n","        return x\n","\n","# Instantiate the model\n","num_features = X_train.shape[1]\n","num_labels = y_train.shape[1]\n","model = MultiLabelNN(num_features, num_labels)\n"],"metadata":{"id":"NHp73KBx3odi","executionInfo":{"status":"ok","timestamp":1709529011259,"user_tz":-330,"elapsed":398,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCELoss()\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    for X_batch, y_batch in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","        loss = criterion(outputs, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","    print(f'Epoch {epoch+1}, Loss: {train_loss / len(train_loader)}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTlIZHoEJWzb","executionInfo":{"status":"ok","timestamp":1709533799568,"user_tz":-330,"elapsed":140113,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"c87056e8-c660-4cac-e593-4a64e0022f4e"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.22181892382497548\n","Epoch 2, Loss: 0.1400173008441925\n","Epoch 3, Loss: 0.13308345745591557\n","Epoch 4, Loss: 0.1258752401135549\n","Epoch 5, Loss: 0.1207336154805512\n","Epoch 6, Loss: 0.11587578828344826\n","Epoch 7, Loss: 0.11152808524730827\n","Epoch 8, Loss: 0.10713282446650897\n","Epoch 9, Loss: 0.102343541609139\n","Epoch 10, Loss: 0.09754109088362765\n"]}]},{"cell_type":"code","source":["import time\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCELoss()\n","\n","num_epochs = 20\n","\n","# Start time of the training\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    epoch_start_time = time.time()  # Start time of the current epoch\n","\n","    for X_batch, y_batch in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","        loss = criterion(outputs, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    epoch_duration = time.time() - epoch_start_time\n","    total_estimated_time = epoch_duration * num_epochs\n","    time_elapsed = time.time() - start_time\n","    time_remaining = total_estimated_time - time_elapsed\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss / len(train_loader)}, Time elapsed: {time_elapsed:.2f}s, Estimated time remaining: {time_remaining:.2f}s')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KzmnQPolJyky","executionInfo":{"status":"ok","timestamp":1709533986474,"user_tz":-330,"elapsed":169369,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"6d613bc4-4ad7-4f5c-bcd1-7a77f6a755b2"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20, Loss: 0.09341020888390661, Time elapsed: 11.58s, Estimated time remaining: 219.95s\n","Epoch 2/20, Loss: 0.08944800264444672, Time elapsed: 18.91s, Estimated time remaining: 127.73s\n","Epoch 3/20, Loss: 0.08509783606444087, Time elapsed: 27.64s, Estimated time remaining: 146.87s\n","Epoch 4/20, Loss: 0.08082220465445719, Time elapsed: 36.45s, Estimated time remaining: 139.90s\n","Epoch 5/20, Loss: 0.07688407465314664, Time elapsed: 45.92s, Estimated time remaining: 143.42s\n","Epoch 6/20, Loss: 0.07337320868332847, Time elapsed: 55.72s, Estimated time remaining: 140.26s\n","Epoch 7/20, Loss: 0.06970699619846184, Time elapsed: 63.09s, Estimated time remaining: 84.18s\n","Epoch 8/20, Loss: 0.06618448822688655, Time elapsed: 71.87s, Estimated time remaining: 103.74s\n","Epoch 9/20, Loss: 0.0629823756631182, Time elapsed: 79.32s, Estimated time remaining: 69.78s\n","Epoch 10/20, Loss: 0.06043513970715659, Time elapsed: 88.04s, Estimated time remaining: 86.27s\n","Epoch 11/20, Loss: 0.05751247998295712, Time elapsed: 95.48s, Estimated time remaining: 53.36s\n","Epoch 12/20, Loss: 0.055024857374549915, Time elapsed: 104.20s, Estimated time remaining: 70.10s\n","Epoch 13/20, Loss: 0.053031397873864454, Time elapsed: 111.72s, Estimated time remaining: 38.78s\n","Epoch 14/20, Loss: 0.05096785973037491, Time elapsed: 120.35s, Estimated time remaining: 52.07s\n","Epoch 15/20, Loss: 0.04939788435937978, Time elapsed: 128.31s, Estimated time remaining: 31.05s\n","Epoch 16/20, Loss: 0.048088022938170355, Time elapsed: 136.57s, Estimated time remaining: 28.49s\n","Epoch 17/20, Loss: 0.045929988971402665, Time elapsed: 144.95s, Estimated time remaining: 22.72s\n","Epoch 18/20, Loss: 0.04446768153364919, Time elapsed: 152.86s, Estimated time remaining: 5.35s\n","Epoch 19/20, Loss: 0.04314432067780936, Time elapsed: 161.77s, Estimated time remaining: 16.42s\n","Epoch 20/20, Loss: 0.04195225057231278, Time elapsed: 169.24s, Estimated time remaining: -19.90s\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss\n","import numpy as np\n","\n","# Ensure model is in evaluation mode\n","model.eval()\n","\n","# Containers for predictions and true labels\n","all_preds = []\n","all_true_labels = []\n","\n","# No gradient is needed for evaluation\n","with torch.no_grad():\n","    for X_batch, y_batch in val_loader:\n","        outputs = model(X_batch)\n","        # Convert model outputs to binary values (0 or 1)\n","        predicted = (outputs > 0.5).int()\n","        all_preds.append(predicted)\n","        all_true_labels.append(y_batch.int())\n","\n","# Concatenate all batches\n","all_preds = torch.cat(all_preds, dim=0).cpu().numpy()\n","all_true_labels = torch.cat(all_true_labels, dim=0).cpu().numpy()\n","\n","# Calculate metrics\n","f1 = f1_score(all_true_labels, all_preds, average='micro')\n","precision = precision_score(all_true_labels, all_preds, average='micro')\n","recall = recall_score(all_true_labels, all_preds, average='micro')\n","hammingloss = hamming_loss(all_true_labels, all_preds)\n","\n","print(f'Precision: {precision:.4f}')\n","print(f'Recall: {recall:.4f}')\n","print(f'F1 Score: {f1:.4f}')\n","print(f'Hamming Loss: {hammingloss:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vOT39rsLMjHk","executionInfo":{"status":"ok","timestamp":1709534502665,"user_tz":-330,"elapsed":940,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"24a2bdb0-5d89-4c6b-f186-22053c91004e"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.4076\n","Recall: 0.2601\n","F1 Score: 0.3176\n","Hamming Loss: 0.0479\n"]}]},{"cell_type":"code","source":["# Assuming you've defined a preprocessing function similar to `clean_text` previously\n","\n","test_file_path = '/content/dataset/test.csv'\n","\n","test_df = pd.read_csv(test_file_path)\n","test_df['processed_plot'] = test_df['plot_synopsis'].apply(clean_text)\n","\n","# Vectorize the processed text using the same TF-IDF vectorizer you used for training\n","# IMPORTANT: Use transform() NOT fit_transform(), as you want to use the same vocabulary as your training set\n","X_test_tfidf = tfidf_vectorizer.transform(test_df['processed_plot'])\n"],"metadata":{"id":"AYpoHj0uNLnM","executionInfo":{"status":"ok","timestamp":1709534749347,"user_tz":-330,"elapsed":7563,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["X_test_tensor = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)  # Convert to tensor\n","test_dataset = TensorDataset(X_test_tensor)  # Create dataset without labels\n","test_loader = DataLoader(test_dataset, batch_size=64)  # Create DataLoader\n"],"metadata":{"id":"uJtAq5DRNj8b","executionInfo":{"status":"ok","timestamp":1709534772651,"user_tz":-330,"elapsed":1740,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["model.eval()  # Set the model to evaluation mode\n","test_preds = []\n","\n","with torch.no_grad():\n","    for X_batch, in test_loader:\n","        outputs = model(X_batch)\n","        predicted = (outputs > 0.5).int()  # Apply threshold to get binary predictions\n","        print(predicted.shape)  # Check the shape of predictions per batch\n","        test_preds.append(predicted)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cVrCkzvBNqHe","executionInfo":{"status":"ok","timestamp":1709538426050,"user_tz":-330,"elapsed":2889,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"331d2404-c55f-4ee8-e2ff-3b70f4d8b4f7"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([64, 71])\n","torch.Size([22, 71])\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Assuming `test_preds` contains the binary predictions for the test dataset\n","\n","# Concatenate all batch predictions\n","test_preds_concatenated = torch.cat(tuple(test_preds), dim=0)\n","\n","print(test_preds_concatenated.shape)\n","\n","# Assuming you have the test DataFrame loaded for 'ID' mapping\n","test_df = pd.read_csv(test_file_path)\n","\n","# Assuming your test DataFrame has an 'ID' column that matches the sample submission\n","# If your DataFrame uses a different column name for IDs, adjust 'imdb_id' accordingly\n","ids = test_df['imdb_id'].values\n","\n","\n","# Load the sample submission file again\n","sample_submission_path = '/content/dataset/sample_submission.csv'  # Adjust this path if necessary\n","sample_submission_df = pd.read_csv(sample_submission_path)\n","\n","print( test_preds_concatenated.shape)\n","\n","\n","# Convert binary predictions to a DataFrame\n","# The column names for predictions should match those in the sample submission, excluding the 'ID' column\n","label_columns = sample_submission_df.columns[1:]  # Exclude the 'ID' column\n","predictions_df = pd.DataFrame(test_preds_concatenated.numpy(), columns=label_columns)\n","\n","# Insert the 'ID' column at the beginning of the DataFrame\n","predictions_df.insert(0, 'ID', ids)\n","\n","# Ensure the format matches the sample submission by converting to float\n","# This step may be optional depending on the requirements of the submission platform\n","# predictions_df = predictions_df.astype(float)\n","\n","submission_file_path = '/content/dataset/final_submission.csv'\n","# Save the DataFrame to a CSV file\n","predictions_df.to_csv(submission_file_path, index=False)\n","\n","# Output the path to the saved submission file\n","submission_file_path\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"TSZg565tOtYF","executionInfo":{"status":"ok","timestamp":1709538889961,"user_tz":-330,"elapsed":7,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"afb271f0-94d1-4a2c-eb06-5012f039d416"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2966, 71])\n","torch.Size([2966, 71])\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/dataset/final_submission.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":57}]}]}