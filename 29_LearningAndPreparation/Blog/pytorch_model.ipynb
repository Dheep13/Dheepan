{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      policy_value  policy_type  region  add_ons\n",
      "9254  42379.481451            1       0        0\n",
      "1561  16079.359975            1       2        0\n",
      "1670  15471.463927            1       3        1\n",
      "6087  22244.603839            1       3        0\n",
      "6669  22748.781380            0       2        1\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# data = pd.read_csv('CommissionsDataSet.csv')\n",
    "\n",
    "data = pd.read_csv('synthetic_dataSet.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=['commission'])\n",
    "y = data['commission']\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_features = ['policy_type', 'region', 'add_ons']\n",
    "encoder = LabelEncoder()\n",
    "for feature in categorical_features:\n",
    "    X[feature] = encoder.fit_transform(X[feature])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.head())\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class CommissionPredictor(nn.Module):\n",
    "    def __init__(self, input_dim,l2_reg):\n",
    "        super(CommissionPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Increased number of neurons\n",
    "        self.fc2 = nn.Linear(128, 64)          # Added another hidden layer\n",
    "        self.fc3 = nn.Linear(64, 32)           # Added another hidden layer\n",
    "        self.fc4 = nn.Linear(32, 1)            # Output layer\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_dim = X_train.shape[1]  # Number of input features\n",
    "lr = 0.01# Learning rate\n",
    "num_epochs = 50\n",
    "batch_size = 30\n",
    "l2_reg = 0.001  # L2 regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = CommissionPredictor(input_dim, l2_reg=l2_reg)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 11300.3428\n",
      "Epoch [2/50], Loss: 12380.7520\n",
      "Epoch [3/50], Loss: 12224.2256\n",
      "Epoch [4/50], Loss: 12023.8574\n",
      "Epoch [5/50], Loss: 11942.7695\n",
      "Epoch [6/50], Loss: 11906.9219\n",
      "Epoch [7/50], Loss: 11883.1426\n",
      "Epoch [8/50], Loss: 11887.5762\n",
      "Epoch [9/50], Loss: 11882.2676\n",
      "Epoch [10/50], Loss: 11884.3584\n",
      "Epoch [11/50], Loss: 11879.6221\n",
      "Epoch [12/50], Loss: 11838.2920\n",
      "Epoch [13/50], Loss: 11889.5439\n",
      "Epoch [14/50], Loss: 11890.7822\n",
      "Epoch [15/50], Loss: 11881.0479\n",
      "Epoch [16/50], Loss: 11900.1924\n",
      "Epoch [17/50], Loss: 11913.3799\n",
      "Epoch [18/50], Loss: 11928.7285\n",
      "Epoch [19/50], Loss: 11925.6123\n",
      "Epoch [20/50], Loss: 11934.1904\n",
      "Epoch [21/50], Loss: 11941.2764\n",
      "Epoch [22/50], Loss: 11955.0469\n",
      "Epoch [23/50], Loss: 11961.8467\n",
      "Epoch [24/50], Loss: 11990.0371\n",
      "Epoch [25/50], Loss: 12013.3027\n",
      "Epoch [26/50], Loss: 12039.0107\n",
      "Epoch [27/50], Loss: 12063.0527\n",
      "Epoch [28/50], Loss: 12080.6240\n",
      "Epoch [29/50], Loss: 12091.8760\n",
      "Epoch [30/50], Loss: 12089.0693\n",
      "Epoch [31/50], Loss: 12093.8760\n",
      "Epoch [32/50], Loss: 12089.5479\n",
      "Epoch [33/50], Loss: 12089.5371\n",
      "Epoch [34/50], Loss: 12072.6797\n",
      "Epoch [35/50], Loss: 12064.9043\n",
      "Epoch [36/50], Loss: 12049.9717\n",
      "Epoch [37/50], Loss: 12020.0908\n",
      "Epoch [38/50], Loss: 11986.2871\n",
      "Epoch [39/50], Loss: 11962.1309\n",
      "Epoch [40/50], Loss: 11923.9756\n",
      "Epoch [41/50], Loss: 11891.7109\n",
      "Epoch [42/50], Loss: 11850.5186\n",
      "Epoch [43/50], Loss: 11809.7559\n",
      "Epoch [44/50], Loss: 11769.3848\n",
      "Epoch [45/50], Loss: 11729.6182\n",
      "Epoch [46/50], Loss: 11684.0645\n",
      "Epoch [47/50], Loss: 11624.3809\n",
      "Epoch [48/50], Loss: 11570.4004\n",
      "Epoch [49/50], Loss: 11512.6104\n",
      "Epoch [50/50], Loss: 11457.4111\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        batch_X = X_train_tensor[i:i+batch_size]\n",
    "        batch_y = y_train_tensor[i:i+batch_size]\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 10953.5869\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    test_loss = criterion(predictions.squeeze(), y_test_tensor)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_filename = \"commission_predictor_model.pth\"\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the full file path by joining the current working directory with the file name\n",
    "model_path = os.path.join(current_dir, model_filename)\n",
    "\n",
    "# Save the model to the specified file path\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
